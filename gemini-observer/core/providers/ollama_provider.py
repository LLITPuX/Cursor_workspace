import ollama
import logging
from core.llm_interface import LLMProvider
from typing import List, Dict, Any

from core.prompts import SYSTEM_PROMPT

class OllamaProvider(LLMProvider):
    def __init__(self, host: str = "http://falkordb-ollama:11434", model: str = "gemma2:2b"):
        # Initialize async client
        # Note: In the official python library, 'AsyncClient' is used for async support
        self.client = ollama.AsyncClient(host=host)
        self.model = model
        logging.info(f"OllamaProvider initialized with model: {model} at {host}")

    async def generate_response(self, history: List[Dict[str, Any]]) -> str:
        """
        Generates response using Ollama.
        """
        # Convert internal history format to Ollama format
        # Internal: [{'role': 'user', 'parts': ['text']}, ...]
        # Ollama: [{'role': 'user', 'content': 'text'}, ...]
        
        ollama_messages = []
        
        # Inject System Prompt
        ollama_messages.append({"role": "system", "content": SYSTEM_PROMPT})
        
        for msg in history:
            role = msg.get("role")
            # Map roles: 'model' -> 'assistant'
            if role == "model":
                role = "assistant"
            
            # Ensure valid roles for Ollama (user, assistant, system)
            if role not in ["user", "assistant", "system"]:
                continue

            content = msg.get("parts", [""])[0]
            ollama_messages.append({"role": role, "content": content})

        try:
            logging.info(f"OllamaProvider: Sending request to {self.model}")
            response = await self.client.chat(model=self.model, messages=ollama_messages)
            
            content = response.get('message', {}).get('content', '')
            if not content:
                logging.warning("OllamaProvider: Received empty content")
                return "‚ö†Ô∏è Local Cortex: Empty response received."

            return content + "\n\n(Generated by Local Cortex üß†)"
            
        except Exception as e:
            logging.error(f"OllamaProvider Error: {str(e)}")
            raise e
